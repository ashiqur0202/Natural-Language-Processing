{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80086c2-774e-448f-ac3e-3f5828943705",
   "metadata": {},
   "source": [
    "__Bag of words__\n",
    "\n",
    "Bag of Words (BoW) is a simple and widely used technique in Natural Language Processing (NLP) for representing text data as numerical data. It is a way of extracting features from text and converting them into a format that can be used for machine learning algorithms.\n",
    "\n",
    "The Bag of Words model represents text as a collection of words, ignoring grammar and word order, but keeping track of the number of times each word appears. It creates a vocabulary of unique words from the entire corpus and generates a document-term matrix that contains the frequency of each word in the vocabulary for each document in the corpus.\n",
    "\n",
    "The Bag of Words model has many applications, including sentiment analysis, topic modeling, and text classification. It is often used as a baseline model in NLP because of its simplicity and ease of implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c181b652-1fc6-4fe7-a526-e19f69833ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'lazy': 1, 'dog': 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Sample text\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text.lower())\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "\n",
    "# Create bag of words\n",
    "bow = Counter(words)\n",
    "\n",
    "# Print bag of words\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c41f4c-a2fb-453e-a45e-1ccae6072b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quick': 1, 'brown': 1, 'fox': 1, 'jumped': 1, 'lazy': 1, 'dog': 2, 'slept': 1, 'verandah': 1}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a sample text to process\n",
    "text = \"The quick brown fox jumped over the lazy dog. The dog slept over the verandah.\"\n",
    "\n",
    "# Process the text using the Spacy model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Define a list of stop words to exclude from the bag of words\n",
    "stop_words = ['a', 'an', 'the', 'over']\n",
    "\n",
    "# Create a dictionary to store the bag of words\n",
    "bag_of_words = {}\n",
    "\n",
    "# Loop through the tokens in the document\n",
    "for token in doc:\n",
    "\n",
    "    # Check if the token is a word and not a stop word\n",
    "    if token.is_alpha and token.text.lower() not in stop_words:\n",
    "        \n",
    "        # Convert the word to lower case\n",
    "        word = token.text.lower()\n",
    "\n",
    "        # Add the word to the dictionary if it doesn't already exist\n",
    "        if word not in bag_of_words:\n",
    "            bag_of_words[word] = 1\n",
    "        \n",
    "        # Increment the count for the word if it already exists in the dictionary\n",
    "        else:\n",
    "            bag_of_words[word] += 1\n",
    "\n",
    "# Print the bag of words dictionary\n",
    "print(bag_of_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cab56e-b791-472b-8f24-cf912efdb841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339808b-4610-4305-8fc7-31b165dea34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
