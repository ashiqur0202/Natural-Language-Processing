{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2200a69a-2408-45b5-9545-8d373844d5ad",
   "metadata": {},
   "source": [
    "__Feature Extraction__\n",
    "\n",
    "In natural language processing (NLP), feature extraction is the process of converting raw text data into a set of numerical features that can be used as input for machine learning models. These features capture different aspects of the text such as its vocabulary, syntax, semantics, and context. Feature extraction is a crucial step in NLP tasks such as text classification, sentiment analysis, and information retrieval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b259f5e-5f95-49f7-a189-501abda01188",
   "metadata": {},
   "source": [
    "__eature extraction via frequency__\n",
    "\n",
    "Feature extraction via frequency is a common technique used in Natural Language Processing (NLP) to identify and extract the most relevant features or words from a corpus of text. This is achieved by computing the frequency of each word in the corpus and selecting the most frequent words as features for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3433e-848e-4ab8-a227-d15044d1ea5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Load the Brown Corpus\n",
    "nltk.download('brown')\n",
    "corpus = brown.words()\n",
    "\n",
    "# Create a frequency distribution of words in the corpus\n",
    "freq_dist = nltk.FreqDist(corpus)\n",
    "\n",
    "# Select the 100 most frequent words as features\n",
    "num_features = 100\n",
    "most_common_words = [word for word, freq in freq_dist.most_common(num_features)]\n",
    "\n",
    "print(most_common_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9d423-545f-4c8e-acff-d410d0a02e3d",
   "metadata": {},
   "source": [
    "__Feature extraction via document frequency__\n",
    "\n",
    "Feature extraction via document frequency is a technique used in natural language processing (NLP) to identify the most significant words in a corpus of text. The basic idea is to count the number of documents in which each word appears and use this count to rank the words by their importance. Words that appear in many documents are likely to be common and less informative, while words that appear in fewer documents are likely to be more specific and informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744bddd-9705-475e-a238-e597c205d66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# tokenize and get the frequency distribution of words in the Brown corpus\n",
    "brown_tokens = word_tokenize(' '.join(brown.words()))\n",
    "fd = FreqDist(brown_tokens)\n",
    "\n",
    "# extract the 10 most frequent words\n",
    "most_common_words = fd.most_common(10)\n",
    "print('Most common words:', most_common_words)\n",
    "\n",
    "# extract the 10 most frequent bigrams\n",
    "bigrams = ngrams(brown_tokens, 2)\n",
    "fd_bigrams = FreqDist(bigrams)\n",
    "most_common_bigrams = fd_bigrams.most_common(10)\n",
    "print('Most common bigrams:', most_common_bigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259f963-f009-4917-ad66-19f10154c719",
   "metadata": {},
   "source": [
    "__inverse document frequency__\n",
    "\n",
    "Feature extraction is one of the most important steps in Natural Language Processing (NLP). It is the process of transforming raw text data into numerical features that can be used for machine learning models. One of the commonly used methods for feature extraction is Inverse Document Frequency (IDF).\n",
    "\n",
    "IDF measures the relevance of a word in a document by comparing the frequency of the word in the document with its frequency in the whole corpus. The more frequent a word is in the corpus, the less relevant it is to a specific document, and hence the lower its IDF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f9e00-6b9c-4c4c-b37c-69806103c01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# sample corpus\n",
    "documents = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "# initialize TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit and transform documents\n",
    "tfidf_matrix = tfidf.fit_transform(documents)\n",
    "\n",
    "# get feature names\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "# print feature names and IDF scores\n",
    "for col in tfidf_matrix.nonzero()[1]:\n",
    "    print(f\"{feature_names[col]}: {tfidf_matrix[0, col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35dd1c-f3cd-4db7-a1a2-03ed15f41bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
